---
title: "Particle Cluster Modeling"
author: "Particle Clustering Proj Group"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Overview

**Goal**: Predict 4 summary statistics of particle cluster volume distributions

-   **Mean** ($\mu$): Average cluster volume
-   **Variance** ($\sigma^2$): Variability in cluster sizes
-   **Skewness** ($\gamma$): Asymmetry of distribution
-   **Kurtosis** ($\kappa$): Tail heaviness

**Modeling Pipeline** for each response:

1.  Apply log transformations to handle right skew
2.  Fit full model with 2-way interactions
3.  **Best subset selection + OLS** → Variable selection via AIC
4.  **LASSO on full model** → Automatic variable selection via regularization
5.  **Compare via 10-fold CV** → Select method with lowest CV RMSE
6.  **Two-stage inference** → When LASSO is selected: predictions from LASSO, intervals from OLS proxy
7.  Generate predictions with **95% prediction intervals**

**Two-Stage Approach:** When LASSO is selected, we use LASSO for point predictions but fit OLS on the LASSO-selected variables to obtain valid prediction intervals.

**Hierarchy Principle:** All models enforce hierarchy - if an interaction term is selected, the corresponding main effects must also be included.

**Note on Re:** Although Re only has 3 observed values (90, 224, 398), it is treated as continuous to allow prediction at any Reynolds number. This introduces substantial uncertainty, which we quantify using 95% prediction intervals.

------------------------------------------------------------------------

# 1. Setup

## 1.1 Load Packages

```{r packages}
library(tidyverse)
library(leaps)
library(glmnet)
set.seed(325)
```

## 1.2 Load Data

```{r load_data}
train <- read_csv("data-train-processed.csv")
nrow(train)
```

## 1.3 Transform Predictors

```{r transform_predictors}
train <- train %>%
  mutate(
    Re = as.numeric(Re),
    Fr_invlogit = 1 / (1 + exp(-as.numeric(Fr))),  # handles Inf
    log_St = log(St)
  )
```

## 1.4 Transform Responses

```{r transform_responses}
train <- train %>%
  mutate(
    log_mean = log(mean),
    log_variance = log(variance),
    log_skewness = log(skewness),
    log_kurtosis = log(kurtosis)
  )
```

## 1.5 Helper Functions

```{r helper_cv}
cv_rmse <- function(data, formula, k = 10) {
  n <- nrow(data)
  fold_ids <- sample(rep(1:k, length.out = n))
  data$fold <- fold_ids
  
  cv_errors <- numeric(k)
  
  for(i in 1:k) {
    train_fold <- data[data$fold != i, ]
    test_fold <- data[data$fold == i, ]
    
    model <- lm(formula, data = train_fold)
    preds <- predict(model, newdata = test_fold)
    
    response <- all.vars(formula)[1]
    cv_errors[i] <- mean((test_fold[[response]] - preds)^2)
  }
  
  return(sqrt(mean(cv_errors)))
}
```

```{r helper_subset}
# if interaction is selected, include main effects too
enforce_hierarchy <- function(vars) {
  all_terms <- vars
  interactions <- grep(":", vars, value = TRUE)
  
  if(length(interactions) > 0) {
    for(int in interactions) {
      main_effects <- strsplit(int, ":")[[1]]
      all_terms <- unique(c(all_terms, main_effects))
    }
  }
  
  return(all_terms)
}
```

------------------------------------------------------------------------

# 2. Model 1: MEAN

## 2.1 Fit Full Model

```{r mean_full}
cat("--- Modeling Mean ---\n")

formula_mean_full <- log_mean ~ log_St + Re + Fr_invlogit + log_St:Re + log_St:Fr_invlogit + Re:Fr_invlogit

lm_mean_full <- lm(formula_mean_full, data = train)
cat("Full model R²:", summary(lm_mean_full)$r.squared, "\n")
cat("Full model variables:", length(coef(lm_mean_full)) - 1, "\n")
```

## 2.2 Best Subset Selection

```{r mean_subset}
regfit_mean <- regsubsets(formula_mean_full, data = train, nvmax = 10, method = "exhaustive")
reg_summary_mean <- summary(regfit_mean)

# calculate AIC (not provided by regsubsets, so we compute it)
n <- nrow(train)
k <- 1:length(reg_summary_mean$rss)  # number of variables in each model
aic_vals <- n * log(reg_summary_mean$rss / n) + 2 * (k + 1)  # k+1 for intercept

# best model by AIC
best_size <- which.min(aic_vals)
cat("Best model size:", best_size, "variables\n")

best_vars <- names(coef(regfit_mean, best_size))[-1]
cat("Variables:", paste(best_vars, collapse = ", "))
```

## 2.3 Build Best Model Formula

```{r mean_formula}
# enforce hierarchy
best_vars_hier <- enforce_hierarchy(best_vars)

formula_mean_best <- as.formula(paste("log_mean ~", paste(best_vars_hier, collapse = " + ")))
formula_mean_best
```

## 2.4 Compare OLS vs LASSO

```{r mean_compare}
lm_mean_best <- lm(formula_mean_best, data = train)
cv_ols_mean <- cv_rmse(train, formula_mean_best, k = 10)
cat("OLS CV RMSE:", cv_ols_mean, "\n")

X_mean_full <- model.matrix(formula_mean_full, data = train)[, -1]
y_mean <- train$log_mean
cv_out_mean <- cv.glmnet(X_mean_full, y_mean, alpha = 1, nfolds = 10)
bestlam_mean <- cv_out_mean$lambda.min
cat("Best lambda:", bestlam_mean, "\n")

# get CV RMSE at best lambda
cv_lasso_mean <- sqrt(cv_out_mean$cvm[cv_out_mean$lambda == bestlam_mean])
cat("LASSO CV RMSE:", cv_lasso_mean, "\n")
```

## 2.5 Select Final Model

```{r mean_final}
if(cv_ols_mean < cv_lasso_mean) {
  cat("Selected: OLS\n")
  final_model_mean <- lm_mean_best
  ols_proxy_mean <- lm_mean_best
  use_lasso_mean <- FALSE
} else {
  cat("Selected: LASSO\n")
  
  # fit lasso on full data with best lambda
  lasso_mean <- glmnet(X_mean_full, y_mean, alpha = 1)
  lasso_coefs <- predict(lasso_mean, type = "coefficients", s = bestlam_mean)
  lasso_vars <- rownames(lasso_coefs)[lasso_coefs[,1] != 0][-1]
  
  cat("LASSO selected", length(lasso_vars), "variables\n")
  
  lasso_vars_hier <- enforce_hierarchy(lasso_vars)
  
  # fit OLS on LASSO vars for intervals
  formula_mean_lasso_ols <- as.formula(paste("log_mean ~", paste(lasso_vars_hier, collapse = " + ")))
  ols_proxy_mean <- lm(formula_mean_lasso_ols, data = train)
  
  final_model_mean <- lasso_mean
  use_lasso_mean <- TRUE
}
```

The comparison shows which variable selection approach performs better: explicit subset selection via AIC (OLS) versus regularization-based automatic selection (LASSO). When LASSO is selected, we use a two-stage approach: LASSO identifies important variables, then we fit OLS on those selected variables to obtain valid prediction intervals.

## 2.6 GAM

```{r}
gam_mean <- gam(
  log_mean ~
    s(log_St, k = 10) +           
    s(Re, k = 3) +                
    s(Fr_invlogit, k = 3) +       
    Re:Fr_invlogit,               
  data = train,
  method = "REML",
  select = TRUE
)

summary(gam_mean)
```

# 3. Model 2: VARIANCE

## 3.1 Fit Full Model

```{r var_full}
cat("--- Modeling Variance ---\n")

formula_var_full <- log_variance ~ log_St + Re + Fr_invlogit + log_St:Re + log_St:Fr_invlogit + Re:Fr_invlogit

lm_var_full <- lm(formula_var_full, data = train)
cat("Full model R²:", summary(lm_var_full)$r.squared, "\n")
cat("Full model variables:", length(coef(lm_var_full)) - 1, "\n")
```

## 3.2 Best Subset Selection

```{r var_subset}
regfit_var <- regsubsets(formula_var_full, data = train, nvmax = 10, method = "exhaustive")
reg_summary_var <- summary(regfit_var)

# calculate AIC
n <- nrow(train)
k <- 1:length(reg_summary_var$rss)
aic_vals <- n * log(reg_summary_var$rss / n) + 2 * (k + 1)

best_size <- which.min(aic_vals)
cat("Best model size:", best_size, "variables\n")

best_vars <- names(coef(regfit_var, best_size))[-1]
cat("Variables:", paste(best_vars, collapse = ", "))
```

## 3.3 Build Best Model Formula

```{r var_formula}
best_vars_hier <- enforce_hierarchy(best_vars)

formula_var_best <- as.formula(paste("log_variance ~", paste(best_vars_hier, collapse = " + ")))
formula_var_best
```

## 3.4 Compare OLS vs LASSO

```{r var_compare}
lm_var_best <- lm(formula_var_best, data = train)
cv_ols_var <- cv_rmse(train, formula_var_best, k = 10)
cat("OLS CV RMSE:", cv_ols_var, "\n")

X_var_full <- model.matrix(formula_var_full, data = train)[, -1]
y_var <- train$log_variance
cv_out_var <- cv.glmnet(X_var_full, y_var, alpha = 1, nfolds = 10)
bestlam_var <- cv_out_var$lambda.min
cat("Best lambda:", bestlam_var, "\n")

cv_lasso_var <- sqrt(cv_out_var$cvm[cv_out_var$lambda == bestlam_var])
cat("LASSO CV RMSE:", cv_lasso_var, "\n")
```

## 3.5 Select Final Model

```{r var_final}
if(cv_ols_var < cv_lasso_var) {
  cat("Selected: OLS\n")
  final_model_var <- lm_var_best
  ols_proxy_var <- lm_var_best
  use_lasso_var <- FALSE
} else {
  cat("Selected: LASSO\n")
  
  lasso_var <- glmnet(X_var_full, y_var, alpha = 1)
  lasso_coefs <- predict(lasso_var, type = "coefficients", s = bestlam_var)
  lasso_vars <- rownames(lasso_coefs)[lasso_coefs[,1] != 0][-1]
  
  cat("LASSO selected", length(lasso_vars), "variables\n")
  
  lasso_vars_hier <- enforce_hierarchy(lasso_vars)
  
  formula_var_lasso_ols <- as.formula(paste("log_variance ~", paste(lasso_vars_hier, collapse = " + ")))
  ols_proxy_var <- lm(formula_var_lasso_ols, data = train)
  
  final_model_var <- lasso_var
  use_lasso_var <- TRUE
}
```

------------------------------------------------------------------------

## 3.6 GAM

```{r}
library(mgcv)

gam_variance <- gam(
  log_variance ~
    s(log_St, k = 10) +           
    s(Re, k = 3) +                
    s(Fr_invlogit, k = 3) +       
    Re:Fr_invlogit,               
  data = train,
  method = "REML",
  select = TRUE
)

summary(gam_variance)


```

# 4. Model 3: SKEWNESS

## 4.1 Fit Full Model

```{r skew_full}
cat("--- Modeling Skewness ---\n")

formula_skew_full <- log_skewness ~ log_St + Re + Fr_invlogit + log_St:Re + log_St:Fr_invlogit + Re:Fr_invlogit

lm_skew_full <- lm(formula_skew_full, data = train)
cat("Full model R²:", summary(lm_skew_full)$r.squared, "\n")
cat("Full model variables:", length(coef(lm_skew_full)) - 1, "\n")
```

## 4.2 Best Subset Selection

```{r skew_subset}
regfit_skew <- regsubsets(formula_skew_full, data = train, nvmax = 10, method = "exhaustive")
reg_summary_skew <- summary(regfit_skew)

# calculate AIC
n <- nrow(train)
k <- 1:length(reg_summary_skew$rss)
aic_vals <- n * log(reg_summary_skew$rss / n) + 2 * (k + 1)

best_size <- which.min(aic_vals)
cat("Best model size:", best_size, "variables\n")

best_vars <- names(coef(regfit_skew, best_size))[-1]
cat("Variables:", paste(best_vars, collapse = ", "))
```

## 4.3 Build Best Model Formula

```{r skew_formula}
best_vars_hier <- enforce_hierarchy(best_vars)

formula_skew_best <- as.formula(paste("log_skewness ~", paste(best_vars_hier, collapse = " + ")))
formula_skew_best
```

## 4.4 Compare OLS vs LASSO

```{r skew_compare}
lm_skew_best <- lm(formula_skew_best, data = train)
cv_ols_skew <- cv_rmse(train, formula_skew_best, k = 10)
cat("OLS CV RMSE:", cv_ols_skew, "\n")

X_skew_full <- model.matrix(formula_skew_full, data = train)[, -1]
y_skew <- train$log_skewness
cv_out_skew <- cv.glmnet(X_skew_full, y_skew, alpha = 1, nfolds = 10)
bestlam_skew <- cv_out_skew$lambda.min
cat("Best lambda:", bestlam_skew, "\n")

cv_lasso_skew <- sqrt(cv_out_skew$cvm[cv_out_skew$lambda == bestlam_skew])
cat("LASSO CV RMSE:", cv_lasso_skew, "\n")
```

## 4.5 Select Final Model

```{r skew_final}
if(cv_ols_skew < cv_lasso_skew) {
  cat("Selected: OLS\n")
  final_model_skew <- lm_skew_best
  ols_proxy_skew <- lm_skew_best
  use_lasso_skew <- FALSE
} else {
  cat("Selected: LASSO\n")
  
  lasso_skew <- glmnet(X_skew_full, y_skew, alpha = 1)
  lasso_coefs <- predict(lasso_skew, type = "coefficients", s = bestlam_skew)
  lasso_vars <- rownames(lasso_coefs)[lasso_coefs[,1] != 0][-1]
  
  cat("LASSO selected", length(lasso_vars), "variables\n")
  
  lasso_vars_hier <- enforce_hierarchy(lasso_vars)
  
  formula_skew_lasso_ols <- as.formula(paste("log_skewness ~", paste(lasso_vars_hier, collapse = " + ")))
  ols_proxy_skew <- lm(formula_skew_lasso_ols, data = train)
  
  final_model_skew <- lasso_skew
  use_lasso_skew <- TRUE
}
```

## 4.6 GAM

```{r}
gam_skewness <- gam(
  log_skewness ~
    s(Re, k = 3) +                
    s(Fr_invlogit, k = 3) +       
    Re:Fr_invlogit,               
  data = train,
  method = "REML",
  select = TRUE
)

summary(gam_skewness)
```

------------------------------------------------------------------------

# 5. Model 4: KURTOSIS

## 5.1 Fit Full Model

```{r kurt_full}
cat("--- Modeling Kurtosis ---\n")

formula_kurt_full <- log_kurtosis ~ log_St + Re + Fr_invlogit + log_St:Re + log_St:Fr_invlogit + Re:Fr_invlogit

lm_kurt_full <- lm(formula_kurt_full, data = train)
cat("Full model R²:", summary(lm_kurt_full)$r.squared, "\n")
cat("Full model variables:", length(coef(lm_kurt_full)) - 1, "\n")
```

## 5.2 Best Subset Selection

```{r kurt_subset}
regfit_kurt <- regsubsets(formula_kurt_full, data = train, nvmax = 10, method = "exhaustive")
reg_summary_kurt <- summary(regfit_kurt)

# calculate AIC
n <- nrow(train)
k <- 1:length(reg_summary_kurt$rss)
aic_vals <- n * log(reg_summary_kurt$rss / n) + 2 * (k + 1)

best_size <- which.min(aic_vals)
cat("Best model size:", best_size, "variables\n")

best_vars <- names(coef(regfit_kurt, best_size))[-1]
cat("Variables:", paste(best_vars, collapse = ", "))
```

## 5.3 Build Best Model Formula

```{r kurt_formula}
best_vars_hier <- enforce_hierarchy(best_vars)

formula_kurt_best <- as.formula(paste("log_kurtosis ~", paste(best_vars_hier, collapse = " + ")))
formula_kurt_best
```

## 5.4 Compare OLS vs LASSO

```{r kurt_compare}
lm_kurt_best <- lm(formula_kurt_best, data = train)
cv_ols_kurt <- cv_rmse(train, formula_kurt_best, k = 10)
cat("OLS CV RMSE:", cv_ols_kurt, "\n")

X_kurt_full <- model.matrix(formula_kurt_full, data = train)[, -1]
y_kurt <- train$log_kurtosis
cv_out_kurt <- cv.glmnet(X_kurt_full, y_kurt, alpha = 1, nfolds = 10)
bestlam_kurt <- cv_out_kurt$lambda.min
cat("Best lambda:", bestlam_kurt, "\n")

cv_lasso_kurt <- sqrt(cv_out_kurt$cvm[cv_out_kurt$lambda == bestlam_kurt])
cat("LASSO CV RMSE:", cv_lasso_kurt, "\n")
```

## 5.5 Select Final Model

```{r kurt_final}
if(cv_ols_kurt < cv_lasso_kurt) {
  cat("Selected: OLS\n")
  final_model_kurt <- lm_kurt_best
  ols_proxy_kurt <- lm_kurt_best
  use_lasso_kurt <- FALSE
} else {
  cat("Selected: LASSO\n")
  
  lasso_kurt <- glmnet(X_kurt_full, y_kurt, alpha = 1)
  lasso_coefs <- predict(lasso_kurt, type = "coefficients", s = bestlam_kurt)
  lasso_vars <- rownames(lasso_coefs)[lasso_coefs[,1] != 0][-1]
  
  cat("LASSO selected", length(lasso_vars), "variables\n")
  
  lasso_vars_hier <- enforce_hierarchy(lasso_vars)
  
  formula_kurt_lasso_ols <- as.formula(paste("log_kurtosis ~", paste(lasso_vars_hier, collapse = " + ")))
  ols_proxy_kurt <- lm(formula_kurt_lasso_ols, data = train)
  
  final_model_kurt <- lasso_kurt
  use_lasso_kurt <- TRUE
}
```

## 5.6 GAM

```{r}

gam_kurtosis <- gam(
  log_kurtosis ~
    s(log_St, k = 10) +           
    s(Fr_invlogit, k = 3) +       
    Re:Fr_invlogit +
    log_St:Re,               
  data = train,
  method = "REML",
  select = TRUE
)

summary(gam_kurtosis)

```

------------------------------------------------------------------------

# 6. Model Diagnostics

## 6.1 Residual Plots

```{r diagnostics_resid, fig.height=8, fig.width=10}
par(mfrow = c(2, 2))

plot(lm_mean_best, which = 1, main = "Mean: Residuals vs Fitted")
plot(lm_var_best, which = 1, main = "Variance: Residuals vs Fitted")
plot(lm_skew_best, which = 1, main = "Skewness: Residuals vs Fitted")
plot(lm_kurt_best, which = 1, main = "Kurtosis: Residuals vs Fitted")
```

## 6.2 Q-Q Plots

```{r diagnostics_qq, fig.height=8, fig.width=10}
par(mfrow = c(2, 2))

plot(lm_mean_best, which = 2, main = "Mean: Q-Q Plot")
plot(lm_var_best, which = 2, main = "Variance: Q-Q Plot")
plot(lm_skew_best, which = 2, main = "Skewness: Q-Q Plot")
plot(lm_kurt_best, which = 2, main = "Kurtosis: Q-Q Plot")
```

# 7. Test Set Predictions

## 7.1 Load and Transform Test Data

```{r test_load}
test <- read_csv("data-test.csv")

test <- test %>%
  mutate(
    Re = as.numeric(Re),
    Fr_invlogit = 1 / (1 + exp(-as.numeric(Fr))),
    log_St = log(St)
  )
```

## 7.2 Generate Predictions

```{r test_predict}
# mean
if(use_lasso_mean) {
  test_temp <- test %>% mutate(log_mean = 0)
  X_test_mean <- model.matrix(formula_mean_full, data = test_temp)[, -1]
  pred_mean_log <- predict(final_model_mean, s = bestlam_mean, newx = X_test_mean)[,1]
} else {
  pred_mean_log <- predict(final_model_mean, newdata = test)
}

# variance
if(use_lasso_var) {
  test_temp <- test %>% mutate(log_variance = 0)
  X_test_var <- model.matrix(formula_var_full, data = test_temp)[, -1]
  pred_var_log <- predict(final_model_var, s = bestlam_var, newx = X_test_var)[,1]
} else {
  pred_var_log <- predict(final_model_var, newdata = test)
}

# skewness
if(use_lasso_skew) {
  test_temp <- test %>% mutate(log_skewness = 0)
  X_test_skew <- model.matrix(formula_skew_full, data = test_temp)[, -1]
  pred_skew_log <- predict(final_model_skew, s = bestlam_skew, newx = X_test_skew)[,1]
} else {
  pred_skew_log <- predict(final_model_skew, newdata = test)
}

# kurtosis
if(use_lasso_kurt) {
  test_temp <- test %>% mutate(log_kurtosis = 0)
  X_test_kurt <- model.matrix(formula_kurt_full, data = test_temp)[, -1]
  pred_kurt_log <- predict(final_model_kurt, s = bestlam_kurt, newx = X_test_kurt)[,1]
} else {
  pred_kurt_log <- predict(final_model_kurt, newdata = test)
}

# back-transform
test_predictions <- test %>%
  mutate(
    pred_mean = exp(pred_mean_log),
    pred_variance = exp(pred_var_log),
    pred_skewness = exp(pred_skew_log),
    pred_kurtosis = exp(pred_kurt_log)
  ) %>%
  select(St, Re, Fr, pred_mean, pred_variance, pred_skewness, pred_kurtosis)

head(test_predictions, 10)
```

```{r}
# --- GAM-only predictions ---

# Predict on test set using GAM models
pred_gam_mean <- predict(gam_mean, newdata = test, type = "response")
pred_gam_var  <- predict(gam_variance, newdata = test, type = "response")
pred_gam_skew <- predict(gam_skewness, newdata = test, type = "response")
pred_gam_kurt <- predict(gam_kurtosis, newdata = test, type = "response")

# Back-transform (assuming predictions are on log scale)
test_predictions_gam <- test %>%
  mutate(
    pred_mean = exp(pred_gam_mean),
    pred_variance = exp(pred_gam_var),
    pred_skewness = exp(pred_gam_skew),
    pred_kurtosis = exp(pred_gam_kurt)
  ) %>%
  select(St, Re, Fr, pred_mean, pred_variance, pred_skewness, pred_kurtosis)

# Save as second CSV
write.csv(test_predictions_gam, "test_predictions_gam_only.csv", row.names = FALSE)

# Optional: preview
head(test_predictions_gam, 10)

```

## 7.3 Prediction Intervals

**Note:** Since Re only has 3 observed values (90, 224, 398) but is treated as continuous, there is substantial uncertainty in predictions. Prediction intervals quantify this uncertainty for new observations.

**Two-Stage Approach:** When LASSO is selected, prediction intervals come from OLS fitted on LASSO-selected variables (the OLS proxy), ensuring valid interval estimates.

```{r prediction_intervals}
# mean
pred_mean_pi <- predict(ols_proxy_mean, newdata = test, interval = "prediction", level = 0.95)
mean_intervals <- test %>%
  select(St, Re, Fr) %>%
  mutate(
    pred = exp(pred_mean_log),
    pi_lower = exp(pred_mean_pi[, "lwr"]),
    pi_upper = exp(pred_mean_pi[, "upr"]),
    pi_width = pi_upper - pi_lower
  )

# variance
pred_var_pi <- predict(ols_proxy_var, newdata = test, interval = "prediction", level = 0.95)
var_intervals <- test %>%
  select(St, Re, Fr) %>%
  mutate(
    pred = exp(pred_var_log),
    pi_lower = exp(pred_var_pi[, "lwr"]),
    pi_upper = exp(pred_var_pi[, "upr"]),
    pi_width = pi_upper - pi_lower
  )

# skewness
pred_skew_pi <- predict(ols_proxy_skew, newdata = test, interval = "prediction", level = 0.95)
skew_intervals <- test %>%
  select(St, Re, Fr) %>%
  mutate(
    pred = exp(pred_skew_log),
    pi_lower = exp(pred_skew_pi[, "lwr"]),
    pi_upper = exp(pred_skew_pi[, "upr"]),
    pi_width = pi_upper - pi_lower
  )

# kurtosis
pred_kurt_pi <- predict(ols_proxy_kurt, newdata = test, interval = "prediction", level = 0.95)
kurt_intervals <- test %>%
  select(St, Re, Fr) %>%
  mutate(
    pred = exp(pred_kurt_log),
    pi_lower = exp(pred_kurt_pi[, "lwr"]),
    pi_upper = exp(pred_kurt_pi[, "upr"]),
    pi_width = pi_upper - pi_lower
  )

cat("Average 95% PI widths:\n")
cat("Mean:", mean(mean_intervals$pi_width), "\n")
cat("Variance:", mean(var_intervals$pi_width), "\n")
cat("Skewness:", mean(skew_intervals$pi_width), "\n")
cat("Kurtosis:", mean(kurt_intervals$pi_width), "\n")
```

Prediction intervals capture both model uncertainty and random noise. Wide intervals are expected given the limited Re values and extrapolation involved.

## 7.4 Save Predictions

```{r test_save}
write_csv(test_predictions, "predictions.csv")
```

------------------------------------------------------------------------

# 8. Model Summaries

## 8.1 Mean Model

```{r summary_mean}
summary(final_model_mean)
```

## 8.2 Variance Model

```{r summary_var}
summary(final_model_var)
```

## 8.3 Skewness Model

```{r summary_skew}
summary(final_model_skew)
```

## 8.4 Kurtosis Model

```{r summary_kurt}
summary(final_model_kurt)
coefs_sparse <- coef(lasso_kurt, s = bestlam_kurt)

coefs_mat <- as.matrix(coefs_sparse)
coefs_mat[ coefs_mat != 0 , , drop = FALSE ]
coefs_mat
```

# 8.5 Cross-Validation RMSE Comparison

```{r cv_summary}
cv_rmse(train, formula_mean_best, k = 10)
cv_results <- data.frame(
  Response = c("Mean", "Variance", "Skewness", "Kurtosis"),
  OLS_CV_RMSE = c(cv_ols_mean, cv_ols_var, cv_ols_skew, cv_ols_kurt),
  LASSO_CV_RMSE = c(cv_lasso_mean, cv_lasso_var, cv_lasso_skew, cv_lasso_kurt)
)

cv_results %>%
  mutate(
    Best_Method = ifelse(OLS_CV_RMSE < LASSO_CV_RMSE, "OLS", "LASSO"),
    Best_RMSE = pmin(OLS_CV_RMSE, LASSO_CV_RMSE),
    CV_Diff = abs(OLS_CV_RMSE - LASSO_CV_RMSE)
  )
```

```{r}
cv_gam_mean  <- cv_rmse_gam(train, formula_mean_best,   k = 10)
cv_gam_var   <- cv_rmse_gam(train, formula_var_best,    k = 10)
cv_gam_skew  <- cv_rmse_gam(train, formula_skew_best,   k = 10)
cv_gam_kurt  <- cv_rmse_gam(train, formula_kurt_best,   k = 10)

# Now assemble cv_results including GAM (assuming you already have cv_ols_* and cv_lasso_* variables)
cv_results <- data.frame(
  Response = c("Mean", "Variance", "Skewness", "Kurtosis"),
  OLS_CV_RMSE   = c(cv_ols_mean, cv_ols_var, cv_ols_skew, cv_ols_kurt),
  LASSO_CV_RMSE = c(cv_lasso_mean, cv_lasso_var, cv_lasso_skew, cv_lasso_kurt),
  GAM_CV_RMSE   = c(cv_gam_mean, cv_gam_var, cv_gam_skew, cv_gam_kurt)
) %>%
  rowwise() %>%
  mutate(
    Best_Method = case_when(
      GAM_CV_RMSE < pmin(OLS_CV_RMSE, LASSO_CV_RMSE) ~ "GAM",
      OLS_CV_RMSE < LASSO_CV_RMSE                         ~ "OLS",
      TRUE                                                ~ "LASSO"
    ),
    Best_RMSE = pmin(GAM_CV_RMSE, OLS_CV_RMSE, LASSO_CV_RMSE),
    # CV_Diff = difference between best and the second-best (how much margin the winner has)
    CV_sorted = list(sort(c(OLS_CV_RMSE, LASSO_CV_RMSE, GAM_CV_RMSE))),
    CV_Diff = CV_sorted[[1]][2] - CV_sorted[[1]][1]
  ) %>%
  ungroup() %>%
  select(-CV_sorted)

print(cv_results)
```

The CV RMSE difference between OLS and LASSO shows how much regularization helps (or hurts) for each response. Small differences suggest both methods work similarly well, while larger differences indicate one method is clearly better at handling the bias-variance tradeoff for that particular response.

------------------------------------------------------------------------

# 9. Key Findings & Next Steps

## For Model Interpretation:

1.  **Model Summaries**: Check R², F-statistic, individual coefficient p-values and standard errors
2.  **Residual Diagnostics**: Q-Q plots show normality assumption; residual plots show homoscedasticity
3.  **Coefficient Interpretation**:
    -   On log scale: 1 unit increase in predictor → multiplicative effect on response
    -   Back-transform: Interpret as % change in original scale
    -   Interaction effects: How combined predictor effects differ from additive
4.  **Variable Selection**: Which predictors were selected? Do they make physical sense?
5.  **Prediction Uncertainty**: Are prediction intervals narrow enough to be useful?

## Physical Interpretation to Consider:

-   **Re** (Reynolds number): Turbulence intensity - how does turbulence affect clustering?
-   **Fr** (Froude number): Gravity vs inertia - when does gravity matter for cluster formation?
-   **St** (Stokes number): Particle inertia - do heavier particles cluster differently?
-   **Interactions**: Do particle effects depend on turbulence conditions?
